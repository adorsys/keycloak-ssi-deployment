apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Values.metadata.name }}
  namespace: {{ .Values.metadata.namespace }}
spec:
  template:
    spec:
      initContainers:
      - name: download-env
        image: "{{ .Values.awsCli.image }}"
        command:
          - "sh"
          - "-c"
          - |
            aws s3 cp s3://{{ .Values.awsCli.s3Bucket }}/.env {{ .Values.awsCli.envFilePath }}
        volumeMounts:
          - name: {{ .Values.volumeMounts.name }}
            mountPath: {{ .Values.volumeMounts.mountPath }}
            
      - name: kubectl
        image: "{{ .Values.kubectl.image }}"
        command:
          - "sh"
          - "-c"
          - |
            sleep {{ .Values.kubectl.sleepDuration }}
            echo "Creating configmap..."
            kubectl create configmap keycloak-env-config --from-file={{ .Values.awsCli.envFilePath }} --namespace={{ .Values.metadata.namespace }} --dry-run=client -o yaml | kubectl apply -f -
            if [ $? -eq 0 ]; then
              echo "Configmap created successfully"
            else
              echo "Failed to create configmap"
              exit 1
            fi
        volumeMounts:
          - name: {{ .Values.volumeMounts.name }}
            mountPath: {{ .Values.volumeMounts.mountPath }}

      containers:
      - name: placeholder
        image: "{{ .Values.placeholder.image }}"
        command: ["sh", "-c", "echo 'Job completed' && sleep 1"]

      restartPolicy: {{ .Values.job.restartPolicy }}
      serviceAccountName: {{ .Values.job.serviceAccountName }}
      volumes:
        - name: {{ .Values.volumeMounts.name }}
          emptyDir: {}